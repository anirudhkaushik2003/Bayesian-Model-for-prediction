{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune googlenet in tf\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly distribute images from train and val to random500_0 to random500_19 so that each has 500 images\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def load_isic_2019():\n",
    "    \"\"\"\n",
    "    Load ISIC_2019 dataset and convert it to IIRC format\n",
    "\n",
    "    Args:\n",
    "        root (string): The location of the dataset\n",
    "        intask_valid_train_ratio (float): the percentage of the training set to be taken for the in-task validation set\n",
    "            , a training-like validation set used for valdation during the task training (default: 0.1)\n",
    "        posttask_valid_train_ratio (float): the percentage of the training set to be taken for the post-task validation\n",
    "            set, a test-like validation set used for valdation after the task training (default: 0.1)\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, DatasetStructType]: datasets, a dictionary with the keys corresponding to the four splits (train,\n",
    "        intask_validation, posttask_validation, test), and the values being a list of the samples that belong to\n",
    "        each split (with the images provided in Image.Image type) in the DatasetTypeStruct structure\n",
    "    \"\"\"\n",
    "    raw_data_meta_df = pd.read_csv('../ISIC_2019/ISIC_2019_Training_GroundTruth.csv')\n",
    "\n",
    "    isic_data_map = {\n",
    "        \"MEL\": \"Melanoma\",  \n",
    "        \"NV\": \"Melanocytic_nevus\" ,\n",
    "        \"BCC\": \"Basal_cell_carcinoma\",\n",
    "        \"AK\": \"Actinic_keratosis\",\n",
    "        \"BKL\": \"Benign_keratosis\",\n",
    "        \"DF\": \"Dermatofibroma\",\n",
    "        \"VASC\": \"Vascular_lesion\",\n",
    "        \"SCC\": \"Squamous_cell_carcinoma\"\n",
    "    }\n",
    "    \n",
    "    labels = list(raw_data_meta_df.columns[1:-1])\n",
    "    class_to_idx = {isic_data_map[label]: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    \n",
    "\n",
    "    X = raw_data_meta_df.iloc[:]['image'] # only image names, not actual images\n",
    "    y = raw_data_meta_df.iloc[:, 1:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1, stratify=y)\n",
    "\n",
    "    unknown_labels = []\n",
    "\n",
    "    raw_data_train = []\n",
    "    for ind  in range(len(X_train)):\n",
    "        img_name = X_train.iloc[ind]\n",
    "        labels = y_train.iloc[ind]\n",
    "        label = labels[labels == 1].index[0]\n",
    "            \n",
    "        # image = cv2.imread(os.path.join(\"../ISIC_2019\", \"ISIC_2019_Training_Input\", img_name+\".jpg\"), cv2.IMREAD_COLOR)\n",
    "        # image = cv2.resize(image, (256, 256), cv2.INTER_AREA) # remove later\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "        if label == \"UNK\":\n",
    "            unknown_labels.append(img_name)\n",
    "        else:\n",
    "            label = class_to_idx[isic_data_map[label]] \n",
    "            raw_data_train.append((img_name, label))\n",
    "\n",
    "\n",
    "    raw_data_test = []\n",
    "    for ind  in range(len(X_test)):\n",
    "        img_name = X_test.iloc[ind]\n",
    "        labels = y_test.iloc[ind]\n",
    "        label = labels[labels == 1].index[0]\n",
    "        if label == \"UNK\":\n",
    "            continue\n",
    "        # image = cv2.imread(os.path.join(\"../ISIC_2019\", \"ISIC_2019_Training_Input\", img_name+\".jpg\"), cv2.IMREAD_COLOR)\n",
    "        # image = cv2.resize(image, (256, 256), cv2.INTER_AREA) # remove later, inter area is for making it smaller, for making it larger use inter linear\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "        label = class_to_idx[isic_data_map[label]]\n",
    "        raw_data_test.append((img_name, label))\n",
    "\n",
    "    return raw_data_train, raw_data_test, unknown_labels\n",
    "\n",
    "# def main():\n",
    "\n",
    "#     # path to the directory that contains train and val\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#     # source = os.path.join('..//../ISIC_2019', 'ISIC_2019_Training_Input')\n",
    "#     # target = os.path.join('./', 'random_discovery' )\n",
    "#     # files = os.listdir(source)\n",
    "#     # for file in files[:500]:\n",
    "#     #     print(file)\n",
    "#     #     shutil.copy(os.path.join(source, file), target)\n",
    "\n",
    "# main()\n",
    "raw_data_train, raw_data_test, unknown_labels = load_isic_2019()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load inceptionv3 model with imagenet weights\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# replace fc layer with 8 classes\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "predictions = Dense(8, activation='softmax')(x)\n",
    "\n",
    "# train \n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# train the model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
