{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "# Read image\n",
    "# files  = sorted(glob.glob(\"./chexpert/train/\"))\n",
    "# print(len(files))\n",
    "# for f in tqdm.tqdm(files):\n",
    "#     img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     # resize to 224x224\n",
    "#     img = cv2.resize(img, (224, 224),cv2.INTER_AREA )\n",
    "#     # save over original\n",
    "#     cv2.imwrite(f, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import ResNet101_Weights, resnet101\n",
    "\n",
    "# Load pretrained model\n",
    "model = resnet101(weights=ResNet101_Weights.IMAGENET1K_V2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations:  223414\n",
      "the shape of the training dataset is : (223414, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>68</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>87</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>83</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>83</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path     Sex  Age  \\\n",
       "0  CheXpert-v1.0-small/train/patient00001/study1/...  Female   68   \n",
       "1  CheXpert-v1.0-small/train/patient00002/study2/...  Female   87   \n",
       "2  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
       "3  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
       "4  CheXpert-v1.0-small/train/patient00003/study1/...    Male   41   \n",
       "\n",
       "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
       "0         Frontal    AP         1.0                         NaN           NaN   \n",
       "1         Frontal    AP         NaN                         NaN          -1.0   \n",
       "2         Frontal    AP         NaN                         NaN           NaN   \n",
       "3         Lateral   NaN         NaN                         NaN           NaN   \n",
       "4         Frontal    AP         NaN                         NaN           NaN   \n",
       "\n",
       "   Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
       "0           NaN          NaN    NaN            NaN        NaN          NaN   \n",
       "1           1.0          NaN   -1.0           -1.0        NaN         -1.0   \n",
       "2           1.0          NaN    NaN           -1.0        NaN          NaN   \n",
       "3           1.0          NaN    NaN           -1.0        NaN          NaN   \n",
       "4           NaN          NaN    1.0            NaN        NaN          NaN   \n",
       "\n",
       "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \n",
       "0           0.0               NaN            NaN       NaN              1.0  \n",
       "1           NaN              -1.0            NaN       1.0              NaN  \n",
       "2           NaN               NaN            NaN       1.0              NaN  \n",
       "3           NaN               NaN            NaN       1.0              NaN  \n",
       "4           0.0               NaN            NaN       NaN              NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "my_glob = glob.glob('./CheXpert-v1.0-small/train/patient*/study*/*.jpg')\n",
    "print('Number of Observations: ', len(my_glob)) \n",
    "\n",
    "train_df = pd.read_csv('./CheXpert-v1.0-small/train.csv')\n",
    "print(f'the shape of the training dataset is : {train_df.shape}')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataframe,policy,class_names):\n",
    "    dataset_df = dataframe[dataframe['Frontal/Lateral'] == 'Frontal'] #take frontal pics only\n",
    "    df = dataset_df.sample(frac=1., random_state=1)\n",
    "    df.fillna(0, inplace=True) #fill the with zeros\n",
    "    x_path, y_df = df[\"Path\"].to_numpy(), df[class_names]\n",
    "    class_ones = ['Atelectasis', 'Cardiomegaly']\n",
    "    y = np.empty(y_df.shape, dtype=int)\n",
    "    for i, (index, row) in enumerate(y_df.iterrows()):\n",
    "        labels = []\n",
    "        for cls in class_names:\n",
    "            curr_val = row[cls]\n",
    "            feat_val = 0\n",
    "            if curr_val:\n",
    "                curr_val = float(curr_val)\n",
    "                if curr_val == 1:\n",
    "                    feat_val = 1\n",
    "                elif curr_val == -1:\n",
    "                    if policy == \"ones\":\n",
    "                        feat_val = 1\n",
    "                    elif policy == \"zeroes\":\n",
    "                        feat_val = 0\n",
    "                    elif policy == \"mixed\":\n",
    "                        if cls in class_ones:\n",
    "                            feat_val = 1\n",
    "                        else:\n",
    "                            feat_val = 0\n",
    "                    else:\n",
    "                        feat_val = 0\n",
    "                else:\n",
    "                    feat_val = 0\n",
    "            else:\n",
    "                feat_val = 0\n",
    "            \n",
    "            labels.append(feat_val)\n",
    "            \n",
    "        y[i] = labels\n",
    "        \n",
    "    return x_path,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "policy = ['ones','zeroes','mixed']\n",
    "x_path,labels = prepare_dataset(train_df,policy[-1],class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def load_chexpert():\n",
    "\n",
    "    train_df = pd.read_csv('./chexpert/train.csv')\n",
    "    print(f'the shape of the training dataset is : {train_df.shape}')\n",
    "    paths = train_df['Path'].values\n",
    "\n",
    "    raw_data_train = []\n",
    "    for file in paths:\n",
    "        image_path = file\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_isic_2019()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# dataloader\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    \n",
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225] )\n",
    "])\n",
    "\n",
    "# datasets\n",
    "train_dataset = ISICDataset(train, transform=transform)\n",
    "test_dataset = ISICDataset(test, transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(2048, 8)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    print('\\nTest set: Accuracy: {:.0f}%\\n'.format(\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "def train_model(model, train_loader, test_loader, optimizer, epochs):\n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/100))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        acc = test_model(model, test_loader)\n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(running_loss)\n",
    "\n",
    "    return acc_list, loss_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.803\n",
      "[1,   200] loss: 0.819\n",
      "[1,   300] loss: 0.801\n",
      "[1,   400] loss: 0.804\n",
      "[1,   500] loss: 0.785\n",
      "[1,   600] loss: 0.798\n",
      "[1,   700] loss: 0.781\n",
      "\n",
      "Test set: Accuracy: 74%\n",
      "\n",
      "[2,   100] loss: 0.700\n",
      "[2,   200] loss: 0.712\n",
      "[2,   300] loss: 0.716\n",
      "[2,   400] loss: 0.709\n",
      "[2,   500] loss: 0.702\n",
      "[2,   600] loss: 0.688\n",
      "[2,   700] loss: 0.662\n",
      "\n",
      "Test set: Accuracy: 74%\n",
      "\n",
      "[3,   100] loss: 0.626\n",
      "[3,   200] loss: 0.625\n",
      "[3,   300] loss: 0.619\n",
      "[3,   400] loss: 0.618\n",
      "[3,   500] loss: 0.584\n",
      "[3,   600] loss: 0.620\n",
      "[3,   700] loss: 0.607\n",
      "\n",
      "Test set: Accuracy: 75%\n",
      "\n",
      "[4,   100] loss: 0.534\n",
      "[4,   200] loss: 0.542\n",
      "[4,   300] loss: 0.518\n",
      "[4,   400] loss: 0.522\n",
      "[4,   500] loss: 0.537\n",
      "[4,   600] loss: 0.516\n",
      "[4,   700] loss: 0.502\n",
      "\n",
      "Test set: Accuracy: 76%\n",
      "\n",
      "[5,   100] loss: 0.448\n",
      "[5,   200] loss: 0.442\n",
      "[5,   300] loss: 0.432\n",
      "[5,   400] loss: 0.425\n",
      "[5,   500] loss: 0.451\n",
      "[5,   600] loss: 0.448\n",
      "[5,   700] loss: 0.443\n",
      "\n",
      "Test set: Accuracy: 77%\n",
      "\n",
      "[6,   100] loss: 0.383\n",
      "[6,   200] loss: 0.352\n",
      "[6,   300] loss: 0.352\n",
      "[6,   400] loss: 0.380\n",
      "[6,   500] loss: 0.353\n",
      "[6,   600] loss: 0.346\n",
      "[6,   700] loss: 0.377\n",
      "\n",
      "Test set: Accuracy: 77%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(model, train_dataloader, test_dataloader, optimizer, \u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[21], line 38\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, optimizer, epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 38\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     39\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target)\n\u001b[1;32m     40\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:171\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs[\u001b[39m0\u001b[39m])\n\u001b[1;32m    170\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 171\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_apply(replicas, inputs, kwargs)\n\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather(outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:181\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparallel_apply\u001b[39m(\u001b[39mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids[:\u001b[39mlen\u001b[39;49m(replicas)])\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:81\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     79\u001b[0m         thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     80\u001b[0m     \u001b[39mfor\u001b[39;00m thread \u001b[39min\u001b[39;00m threads:\n\u001b[0;32m---> 81\u001b[0m         thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m     82\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     _worker(\u001b[39m0\u001b[39m, modules[\u001b[39m0\u001b[39m], inputs[\u001b[39m0\u001b[39m], kwargs_tup[\u001b[39m0\u001b[39m], devices[\u001b[39m0\u001b[39m], streams[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1117\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, test_dataloader, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 78%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7770323599052881"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.module.state_dict(), \"../project-in-medical-image-computing-anirudhkaushik2003/src/feature_extractor/chexpert_feature_extractor.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
