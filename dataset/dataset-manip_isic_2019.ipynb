{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25331/25331 [06:33<00:00, 64.40it/s] \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "# Read image\n",
    "files  = sorted(glob.glob(\"./ISIC_2019/ISIC_2019_Training_Input/*.jpg\"))\n",
    "print(len(files))\n",
    "for f in tqdm.tqdm(files):\n",
    "    img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # resize to 224x224\n",
    "    img = cv2.resize(img, (224, 224),cv2.INTER_AREA )\n",
    "    # save over original\n",
    "    cv2.imwrite(f, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import ResNet101_Weights, resnet101\n",
    "\n",
    "# Load pretrained model\n",
    "model = resnet101(weights=ResNet101_Weights.IMAGENET1K_V2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n",
      "image                                                     \n",
      "ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = \n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "def load_isic_2019():\n",
    "    \"\"\"\n",
    "    Load ISIC_2019 dataset and convert it to IIRC format\n",
    "\n",
    "    Args:\n",
    "        root (string): The location of the dataset\n",
    "        intask_valid_train_ratio (float): the percentage of the training set to be taken for the in-task validation set\n",
    "            , a training-like validation set used for valdation during the task training (default: 0.1)\n",
    "        posttask_valid_train_ratio (float): the percentage of the training set to be taken for the post-task validation\n",
    "            set, a test-like validation set used for valdation after the task training (default: 0.1)\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, DatasetStructType]: datasets, a dictionary with the keys corresponding to the four splits (train,\n",
    "        intask_validation, posttask_validation, test), and the values being a list of the samples that belong to\n",
    "        each split (with the images provided in Image.Image type) in the DatasetTypeStruct structure\n",
    "    \"\"\"\n",
    "    raw_data_meta_df = pd.read_csv('./ISIC_2019/ISIC_2019_Training_GroundTruth.csv')\n",
    "\n",
    "    isic_data_map = {\n",
    "        \"MEL\": \"Melanoma\",  \n",
    "        \"NV\": \"Melanocytic_nevus\" ,\n",
    "        \"BCC\": \"Basal_cell_carcinoma\",\n",
    "        \"AK\": \"Actinic_keratosis\",\n",
    "        \"BKL\": \"Benign_keratosis\",\n",
    "        \"DF\": \"Dermatofibroma\",\n",
    "        \"VASC\": \"Vascular_lesion\",\n",
    "        \"SCC\": \"Squamous_cell_carcinoma\"\n",
    "    }\n",
    "    \n",
    "    labels = list(raw_data_meta_df.columns[1:-1])\n",
    "    class_to_idx = {isic_data_map[label]: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    \n",
    "\n",
    "    X = raw_data_meta_df.iloc[:]['image'] # only image names, not actual images\n",
    "    y = raw_data_meta_df.iloc[:, 1:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1, stratify=y)\n",
    "\n",
    "    raw_data_train = []\n",
    "    for ind  in range(len(X_train)):\n",
    "        img_name = X_train.iloc[ind]\n",
    "        labels = y_train.iloc[ind]\n",
    "        label = labels[labels == 1].index[0]\n",
    "        if label == \"UNK\":\n",
    "            continue\n",
    "        image = cv2.imread(os.path.join(\"./ISIC_2019\", \"ISIC_2019_Training_Input\", img_name+\".jpg\"), cv2.IMREAD_COLOR)\n",
    "        # image = cv2.resize(image, (256, 256), cv2.INTER_AREA) # remove later\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "        label = class_to_idx[isic_data_map[label]] \n",
    "        raw_data_train.append((image, label))\n",
    "\n",
    "\n",
    "    raw_data_test = []\n",
    "    for ind  in range(len(X_test)):\n",
    "        img_name = X_test.iloc[ind]\n",
    "        labels = y_test.iloc[ind]\n",
    "        label = labels[labels == 1].index[0]\n",
    "        if label == \"UNK\":\n",
    "            continue\n",
    "        image = cv2.imread(os.path.join(\"./ISIC_2019\", \"ISIC_2019_Training_Input\", img_name+\".jpg\"), cv2.IMREAD_COLOR)\n",
    "        # image = cv2.resize(image, (256, 256), cv2.INTER_AREA) # remove later, inter area is for making it smaller, for making it larger use inter linear\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "        label = class_to_idx[isic_data_map[label]]\n",
    "        raw_data_test.append((image, label))\n",
    "\n",
    "    return raw_data_train, raw_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_isic_2019()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# dataloader\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    \n",
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225] )\n",
    "])\n",
    "\n",
    "# datasets\n",
    "train_dataset = ISICDataset(train, transform=transform)\n",
    "test_dataset = ISICDataset(test, transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(2048, 8)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    print('\\nTest set: Accuracy: {:.0f}%\\n'.format(\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "def train_model(model, train_loader, test_loader, optimizer, epochs):\n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/100))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        acc = test_model(model, test_loader)\n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(running_loss)\n",
    "\n",
    "    return acc_list, loss_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.803\n",
      "[1,   200] loss: 0.819\n",
      "[1,   300] loss: 0.801\n",
      "[1,   400] loss: 0.804\n",
      "[1,   500] loss: 0.785\n",
      "[1,   600] loss: 0.798\n",
      "[1,   700] loss: 0.781\n",
      "\n",
      "Test set: Accuracy: 74%\n",
      "\n",
      "[2,   100] loss: 0.700\n",
      "[2,   200] loss: 0.712\n",
      "[2,   300] loss: 0.716\n",
      "[2,   400] loss: 0.709\n",
      "[2,   500] loss: 0.702\n",
      "[2,   600] loss: 0.688\n",
      "[2,   700] loss: 0.662\n",
      "\n",
      "Test set: Accuracy: 74%\n",
      "\n",
      "[3,   100] loss: 0.626\n",
      "[3,   200] loss: 0.625\n",
      "[3,   300] loss: 0.619\n",
      "[3,   400] loss: 0.618\n",
      "[3,   500] loss: 0.584\n",
      "[3,   600] loss: 0.620\n",
      "[3,   700] loss: 0.607\n",
      "\n",
      "Test set: Accuracy: 75%\n",
      "\n",
      "[4,   100] loss: 0.534\n",
      "[4,   200] loss: 0.542\n",
      "[4,   300] loss: 0.518\n",
      "[4,   400] loss: 0.522\n",
      "[4,   500] loss: 0.537\n",
      "[4,   600] loss: 0.516\n",
      "[4,   700] loss: 0.502\n",
      "\n",
      "Test set: Accuracy: 76%\n",
      "\n",
      "[5,   100] loss: 0.448\n",
      "[5,   200] loss: 0.442\n",
      "[5,   300] loss: 0.432\n",
      "[5,   400] loss: 0.425\n",
      "[5,   500] loss: 0.451\n",
      "[5,   600] loss: 0.448\n",
      "[5,   700] loss: 0.443\n",
      "\n",
      "Test set: Accuracy: 77%\n",
      "\n",
      "[6,   100] loss: 0.383\n",
      "[6,   200] loss: 0.352\n",
      "[6,   300] loss: 0.352\n",
      "[6,   400] loss: 0.380\n",
      "[6,   500] loss: 0.353\n",
      "[6,   600] loss: 0.346\n",
      "[6,   700] loss: 0.377\n",
      "\n",
      "Test set: Accuracy: 77%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(model, train_dataloader, test_dataloader, optimizer, \u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[21], line 38\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, optimizer, epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 38\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     39\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target)\n\u001b[1;32m     40\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:171\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs[\u001b[39m0\u001b[39m])\n\u001b[1;32m    170\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 171\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_apply(replicas, inputs, kwargs)\n\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather(outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:181\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparallel_apply\u001b[39m(\u001b[39mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids[:\u001b[39mlen\u001b[39;49m(replicas)])\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:81\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     79\u001b[0m         thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     80\u001b[0m     \u001b[39mfor\u001b[39;00m thread \u001b[39min\u001b[39;00m threads:\n\u001b[0;32m---> 81\u001b[0m         thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m     82\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     _worker(\u001b[39m0\u001b[39m, modules[\u001b[39m0\u001b[39m], inputs[\u001b[39m0\u001b[39m], kwargs_tup[\u001b[39m0\u001b[39m], devices[\u001b[39m0\u001b[39m], streams[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1117\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, test_dataloader, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 78%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7770323599052881"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.module.state_dict(), \"../project-in-medical-image-computing-anirudhkaushik2003/src/feature_extractor/isic_feature_extractor.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
